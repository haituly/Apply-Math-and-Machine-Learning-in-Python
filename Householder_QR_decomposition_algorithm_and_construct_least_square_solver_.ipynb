{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNNDiMesxgFLdAWByxVFPxT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haituly/Apply-Math-and-Machine-Learning-in-Python/blob/main/Householder_QR_decomposition_algorithm_and_construct_least_square_solver_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Coding Householder Reflections\n",
        "# We write a function reflectMult(A,w) that takes in an m × n matrix A and maps its columns via the Householder transformation \n",
        "# that reflects across the plane perpendicular to w (do not assume its a unit vector)\n",
        "import numpy as np\n",
        "def reflectMult(A,w):\n",
        "    w /= np.linalg.norm(w)\n",
        "    A-= 2*np.outer(w,w@A)\n",
        "\n",
        "# Validate our code\n",
        "for i in range(50):\n",
        "  A=np.random.rand(100,50)\n",
        "  B=np.copy(A)\n",
        "  reflectMult(B,np.eye(100)[:,i]-B[:,i]/np.linalg.norm(B[:,i]))\n",
        "  print(np.allclose(B[:,i],np.eye(100)[:,i]*np.linalg.norm(A[:,i])))\n",
        "  print(np.allclose(np.linalg.norm(B),np.linalg.norm(A)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUuVmDo5tj79",
        "outputId": "5a792369-26ff-43dd-e1b8-571b1e1e39d7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Coding the Householder QR Algorithm\n",
        "def sgn(x):\n",
        "    if x==0:\n",
        "        return 1\n",
        "    else:\n",
        "        return np.sign(x)\n",
        "\n",
        "# We create myQR(A) function which takes in an m × n matrix A and returns an m × n matrix q and n × n matrix R\n",
        "# Matrix R contains direction for the Householder reflection\n",
        "def myQR(A):\n",
        "    m,n=A.shape\n",
        "    R=np.copy(A)\n",
        "    q=np.zeros((m,n))\n",
        "    for i in range(n):\n",
        "        tau=np.linalg.norm(R[i:,i])\n",
        "        q[i:,i]=R[i:,i]\n",
        "        q[i,i]+=sgn(R[i,i])*tau\n",
        "        reflectMult(R[i:,i:],q[i:,i])\n",
        "    return q, R[:n,:n]\n",
        "# Before validating our code, we need to active the assembleQ(q) function\n",
        "# It will \n",
        "def assembleQ(q):\n",
        "  m,n=q.shape\n",
        "  Q=np.eye(m)\n",
        "  for i in range(n):\n",
        "     reflectMult(Q,q[:,n-1-i])\n",
        "  return Q\n",
        "\n",
        "#Validating our code\n",
        "A=np.random.rand(100,50)\n",
        "q,R=myQR(A)\n",
        "Q=assembleQ(q)\n",
        "np.allclose(Q[:,:50]@R,A)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzTAL1dHt-uI",
        "outputId": "5a547f0f-ca5c-4728-b1c1-15fcd9ca68d5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Coding Least Squares\n",
        "# We will need upperbSub function to construct least square algorithm\n",
        "def upperbSub(A,b):\n",
        "  n=len(A)\n",
        "  x=np.zeros(n)\n",
        "  x[n-1]=b[n-1]/A[n-1,n-1]\n",
        "  for i in range(1,len(A)):\n",
        "    x[n-1-i]=1/A[n-1-i,n-1-i]*(b[n-1-i]-np.dot(A[n-1-i,n-i:],x[n-i:]))\n",
        "  return x\n",
        "\n",
        "# myLS function will take in an m × n matrix A for m ≥ n and m-dimensional vector b \n",
        "# and returns an n-dimensional vector x which is a solution to the least squares problem \n",
        "# Rˆx = QˆT b where A = QˆRˆ is the condensed QR decomposition of A\n",
        "def myLS(A,b):\n",
        "  q,R=myQR(A)\n",
        "  Q=assembleQ(q)\n",
        "  p=(Q.transpose())@b\n",
        "  return upperbSub(R,p)\n",
        "\n",
        "#Validating code\n",
        "A=np.random.rand(100,50)\n",
        "b=np.random.rand(100)\n",
        "x=myLS(A,b)\n",
        "np.allclose(x,np.linalg.lstsq(A,b,rcond=None)[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQtR6pN_uZCv",
        "outputId": "89a20211-675c-43eb-a475-6cb75b7c154d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YAKDsfqpjppm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}